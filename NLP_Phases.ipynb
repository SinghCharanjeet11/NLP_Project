{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzQyDxLM+O924uNU6FXqfW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SinghCharanjeet11/NLP_Project/blob/main/NLP_Phases.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NLP Phase -01 Text Processing"
      ],
      "metadata": {
        "id": "5-L8xyGUR93N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Text -> Cleaning -> Tokenizaton -> Stopwords Removal -> Stemming -> Calling"
      ],
      "metadata": {
        "id": "8NfjlqbeSFvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text= \"I am learning Python programming and Python is fast!!...\"\n",
        "print(\"Original text : \",text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WC6-YvGUST0w",
        "outputId": "053e3795-5515-4eca-d91d-c2b74c896023"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text :  I am learning Python programming and Python is fast!!...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-1 Convert to lower case\n",
        "text=text.lower()\n",
        "#Python !=python\n",
        "print(\"Lowercase: \",text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dhgoSDPSkax",
        "outputId": "dfde916d-215e-4085-f1ea-a4bbf820a3c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lowercase:  i am learning python programming and python is fast!!...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step- 2: Remove punctuation - !@#$%^&*();'.,\n",
        "#Regex- Regular Expression\n",
        "import re\n",
        "text=re.sub(r'[^\\w\\s]',' ',text)\n",
        "print(\"Without punctuation: \",text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6c3t-WiTCsM",
        "outputId": "76928a32-88e9-41b7-f350-fa25862c4bef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Without punctuation:  i am learning python programming and python is fast     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step -3 Tokenization\n",
        "tokens=text.split()\n",
        "print(\"Tokens: \",tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_3fdR6iWh6K",
        "outputId": "1af13034-19d4-4f80-8f65-d5eb5d976098"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens:  ['i', 'am', 'learning', 'python', 'programming', 'and', 'python', 'is', 'fast']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step- 4 Remove StopWords like is, am, are, the, a, an\n",
        "stopwords=[\"a\",\"is\",\"am\",\"i\",\"the\",\"and\"]\n",
        "\n",
        "filtered_tokens=[]\n",
        "for word in tokens:\n",
        "  if word not in stopwords:\n",
        "    filtered_tokens.append(word)\n",
        "print(\"After removeing the stopwords: \",filtered_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCO57acPWwsT",
        "outputId": "8822418f-45a5-4af7-82b8-eea7b7570d77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After removeing the stopwords:  ['learning', 'python', 'programming', 'python', 'fast']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def stem(word):\n",
        "  if word.endswith(\"ing\"):\n",
        "    return word[:-3]\n",
        "  return word\n",
        "stemmed_words=[]\n",
        "for word in filtered_tokens:\n",
        "    stemmed_words.append(stem(word))\n",
        "print(\"After stemming: \",stemmed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egvL8u96XdZ1",
        "outputId": "c29c7f26-0aa3-4279-9ff4-6a2275827a67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After stemming:  ['learn', 'python', 'programm', 'python', 'fast']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NLP Phase -2: WORD TO VECTOR\n"
      ],
      "metadata": {
        "id": "Aa-rQNijYkOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Why vectors??\n",
        "# ML models only understand numbers\n"
      ],
      "metadata": {
        "id": "30Sj6RTEYqia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Will convert text -> count\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "0voEt8ksY6JN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences=[ \"i am learning python and python\",\n",
        "           \"we are happy today\",\n",
        "            \"i am sad today\"\n",
        "            ]"
      ],
      "metadata": {
        "id": "dNd2cJpNZrol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer=CountVectorizer() #create object\n",
        "X=vectorizer.fit_transform(sentences)\n",
        "# learn vocabulary\n",
        "# convert sentences to numbers\n",
        "#Remove single letters like i,a\n",
        "print(\"Vocabulary : \",vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mro82-LZenG",
        "outputId": "db960200-b0cf-4922-efb0-baea7b8d8902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary :  ['am' 'and' 'are' 'happy' 'learning' 'python' 'sad' 'today' 'we']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Vectors:\")\n",
        "print(X.toarray())\n",
        "#Each row is a sentence\n",
        "# Each column is a word\n",
        "# Each value is a count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Hf8t4lNZdFk",
        "outputId": "b2a23d67-3fdd-404f-816a-b7d74396ee81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectors:\n",
            "[[1 1 0 0 1 2 0 0 0]\n",
            " [0 0 1 1 0 0 0 1 1]\n",
            " [1 0 0 0 0 0 1 1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF= Term Frequency Inverse Documnent Frequency\n"
      ],
      "metadata": {
        "id": "NtkBestmcc4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Why TF-IDF?\n",
        "# Because count is not enough\n",
        "# Bag of words treats all words equally"
      ],
      "metadata": {
        "id": "k887PcNKcn28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "ObiQ7-3mcy7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences=[ \"i am learning python and python\",\n",
        "           \"we are happy today\",\n",
        "            \"i am sad today\"\n",
        "            ]"
      ],
      "metadata": {
        "id": "0aPoF5zydDeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer=TfidfVectorizer()\n",
        "X= vectorizer.fit_transform(sentences)\n",
        "# build vocabulary\n",
        "# calculate TF\n",
        "# calculate idf - impact of each word\n",
        "# multiplies tf x idf\n",
        "# produces matrix"
      ],
      "metadata": {
        "id": "xBjQmJtfdDwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Vocabulary: \", vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srv_avvxeTW-",
        "outputId": "40555bfc-a023-43dd-9469-7277008e2bc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary:  ['am' 'and' 'are' 'happy' 'learning' 'python' 'sad' 'today' 'we']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"TF-IDF Matrix: \")\n",
        "print(X.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaRNVJ-refcd",
        "outputId": "563ee5a4-f1ba-4787-ddba-14aa3d0797af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Matrix: \n",
            "[[0.29651988 0.38988801 0.         0.         0.38988801 0.77977602\n",
            "  0.         0.         0.        ]\n",
            " [0.         0.         0.52863461 0.52863461 0.         0.\n",
            "  0.         0.40204024 0.52863461]\n",
            " [0.51785612 0.         0.         0.         0.         0.\n",
            "  0.68091856 0.51785612 0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count+Impact of eeach word\n",
        "# TF-IDF reawrds are important wordsa and peanlizes common words\n",
        "# TF= COUNT(WORDS)/total_words\n",
        "#IDF= log(total_docs/docs_with_word)\n",
        "\n"
      ],
      "metadata": {
        "id": "rozfJGrqfJ1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y5ypE2yIfU_t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}